{
  "version": "1.0.0",
  "lastUpdated": "2025-06-28",
  "description": "Default pricing data for common AI providers - used as fallback and initial seed",
  "providers": {
    "openai": {
      "display_name": "OpenAI",
      "description": "Leading AI research company with GPT models",
      "website": "https://openai.com/pricing",
      "status": "active",
      "models": {
        "gpt-4": {
          "display_name": "GPT-4",
          "description": "GPT-4 with 8K context window",
          "input_price_per_1m_tokens": 30.0,
          "output_price_per_1m_tokens": 60.0,
          "context_window": 8192,
          "max_tokens": 4096,
          "is_active": true
        },
        "gpt-4-turbo": {
          "display_name": "GPT-4 Turbo",
          "description": "GPT-4 Turbo with 128K context window",
          "input_price_per_1m_tokens": 10.0,
          "output_price_per_1m_tokens": 30.0,
          "context_window": 128000,
          "max_tokens": 4096,
          "is_active": true
        },
        "gpt-3.5-turbo": {
          "display_name": "GPT-3.5 Turbo",
          "description": "Fast and efficient GPT-3.5 model",
          "input_price_per_1m_tokens": 1.5,
          "output_price_per_1m_tokens": 2.0,
          "context_window": 16385,
          "max_tokens": 4096,
          "is_active": true
        }
      },
      "media_pricing": {
        "image": {
          "pricing_model": "per_unit",
          "base_cost": 0.02,
          "resolution_multipliers": {
            "512x512": 1.0,
            "1024x1024": 1.5,
            "1792x1024": 2.0,
            "1024x1792": 2.0
          },
          "quality_multipliers": {
            "low": 0.8,
            "medium": 1.0,
            "high": 1.3
          }
        }
      }
    },
    "anthropic": {
      "display_name": "Anthropic",
      "description": "AI safety research company with Claude models",
      "website": "https://www.anthropic.com/pricing",
      "status": "active",
      "models": {
        "claude-3-opus": {
          "display_name": "Claude 3 Opus",
          "description": "Most capable Claude model for complex tasks",
          "input_price_per_1m_tokens": 15.0,
          "output_price_per_1m_tokens": 75.0,
          "context_window": 200000,
          "max_tokens": 4096,
          "is_active": true
        },
        "claude-3-sonnet": {
          "display_name": "Claude 3 Sonnet",
          "description": "Balanced Claude model for general use",
          "input_price_per_1m_tokens": 3.0,
          "output_price_per_1m_tokens": 15.0,
          "context_window": 200000,
          "max_tokens": 4096,
          "is_active": true
        },
        "claude-3-haiku": {
          "display_name": "Claude 3 Haiku",
          "description": "Fast and efficient Claude model",
          "input_price_per_1m_tokens": 0.25,
          "output_price_per_1m_tokens": 1.25,
          "context_window": 200000,
          "max_tokens": 4096,
          "is_active": true
        }
      }
    },
    "google": {
      "display_name": "Google AI",
      "description": "Google's AI research division with Gemini models",
      "website": "https://ai.google.dev/pricing",
      "status": "active",
      "models": {
        "gemini-pro": {
          "display_name": "Gemini Pro",
          "description": "Google's most capable text model",
          "input_price_per_1m_tokens": 0.5,
          "output_price_per_1m_tokens": 1.5,
          "context_window": 32768,
          "max_tokens": 2048,
          "is_active": true
        },
        "gemini-pro-vision": {
          "display_name": "Gemini Pro Vision",
          "description": "Multimodal model for text and image",
          "input_price_per_1m_tokens": 0.5,
          "output_price_per_1m_tokens": 1.5,
          "context_window": 32768,
          "max_tokens": 2048,
          "is_active": true
        }
      },
      "media_pricing": {
        "image": {
          "pricing_model": "per_unit",
          "base_cost": 0.015,
          "resolution_multipliers": {
            "1024x1024": 1.0,
            "1792x1024": 1.5,
            "1024x1792": 1.5
          },
          "quality_multipliers": {
            "low": 0.8,
            "medium": 1.0,
            "high": 1.2
          }
        }
      }
    },
    "mistral": {
      "display_name": "Mistral AI",
      "description": "European AI company with open and commercial models",
      "website": "https://mistral.ai/pricing",
      "status": "active",
      "models": {
        "mistral-large": {
          "display_name": "Mistral Large",
          "description": "Most capable Mistral model",
          "input_price_per_1m_tokens": 6.0,
          "output_price_per_1m_tokens": 24.0,
          "context_window": 32768,
          "max_tokens": 4096,
          "is_active": true
        },
        "mistral-medium": {
          "display_name": "Mistral Medium",
          "description": "Balanced Mistral model",
          "input_price_per_1m_tokens": 2.7,
          "output_price_per_1m_tokens": 8.1,
          "context_window": 32768,
          "max_tokens": 4096,
          "is_active": true
        },
        "mistral-small": {
          "display_name": "Mistral Small",
          "description": "Fast and efficient Mistral model",
          "input_price_per_1m_tokens": 0.14,
          "output_price_per_1m_tokens": 0.42,
          "context_window": 32768,
          "max_tokens": 4096,
          "is_active": true
        }
      }
    },
    "cohere": {
      "display_name": "Cohere",
      "description": "Enterprise-focused AI company",
      "website": "https://cohere.com/pricing",
      "status": "active",
      "models": {
        "command": {
          "display_name": "Command",
          "description": "Cohere's flagship text generation model",
          "input_price_per_1m_tokens": 15.0,
          "output_price_per_1m_tokens": 60.0,
          "context_window": 32768,
          "max_tokens": 4096,
          "is_active": true
        },
        "command-light": {
          "display_name": "Command Light",
          "description": "Faster and more cost-effective Command model",
          "input_price_per_1m_tokens": 3.0,
          "output_price_per_1m_tokens": 15.0,
          "context_window": 32768,
          "max_tokens": 4096,
          "is_active": true
        }
      }
    },
    "meta": {
      "display_name": "Meta",
      "description": "Self-hosted models and research",
      "website": null,
      "status": "active",
      "models": {
        "llama-2-70b": {
          "display_name": "Llama 2 70B",
          "description": "Large self-hosted model (estimated costs)",
          "input_price_per_1m_tokens": 0.7,
          "output_price_per_1m_tokens": 0.8,
          "context_window": 4096,
          "max_tokens": 4096,
          "is_active": true
        },
        "llama-2-13b": {
          "display_name": "Llama 2 13B",
          "description": "Medium self-hosted model (estimated costs)",
          "input_price_per_1m_tokens": 0.3,
          "output_price_per_1m_tokens": 0.4,
          "context_window": 4096,
          "max_tokens": 4096,
          "is_active": true
        }
      }
    }
  },
  "metadata": {
    "updateFrequency": "weekly",
    "dataSource": "default_file",
    "notes": "Default pricing data - will be overridden by database values when available"
  }
} 